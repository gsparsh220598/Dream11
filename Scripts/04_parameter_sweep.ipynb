{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git clone --recursive https://github.com/microsoft/LightGBM\n",
    "# !cd LightGBM\n",
    "# !mkdir build\n",
    "# !cd build\n",
    "# !cmake -DUSE_CUDA=1 ..\n",
    "# !make -j4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import wandb\n",
    "import warnings\n",
    "# from utility import *\n",
    "\n",
    "environment = 'local'\n",
    "if environment == 'paperspace':\n",
    "    os.chdir('/notebooks/Scripts')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler, PolynomialFeatures, SplineTransformer, KBinsDiscretizer, \\\n",
    "     StandardScaler, OrdinalEncoder, LabelEncoder\n",
    "from sklearn.feature_selection import SelectKBest, f_regression, r_regression, mutual_info_regression, SelectFromModel\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import mean_absolute_error, r2_score, get_scorer_names, accuracy_score, f1_score, precision_score, \\\n",
    "     confusion_matrix, recall_score\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split, StratifiedKFold, cross_validate, TimeSeriesSplit\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsRegressor, LocalOutlierFactor\n",
    "import sklearn.linear_model as lm\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier, ExtraTreesClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from hyperparams import *\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "warnings.filterwarnings('ignore')\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "wandb version 0.15.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/sparshgupta/Projects git/Dream11/Scripts/wandb/run-20230501_174844-gnrcjgry</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/gsparsh/Dream11/runs/gnrcjgry' target=\"_blank\">atomic-silence-36</a></strong> to <a href='https://wandb.ai/gsparsh/Dream11' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/gsparsh/Dream11' target=\"_blank\">https://wandb.ai/gsparsh/Dream11</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/gsparsh/Dream11/runs/gnrcjgry' target=\"_blank\">https://wandb.ai/gsparsh/Dream11/runs/gnrcjgry</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run = wandb.init(\n",
    "  project=\"Dream11\", entity=None, job_type=\"modeling\",\n",
    "  notes=\"Modelling the Dream11 dataset (~40 games) with LGBMClassifier (7 classes) with feature embeddings\",\n",
    "  # notes = \"setting benchmark using a Naive Classifier\",\n",
    "  tags=[\"embeddings\", \"multiclass_classification\", \"imbalanced_data\", \\\n",
    "        \"random_search\", \"LGBMClassifier\", \"StratifiedKFold\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if environment == 'local':\n",
    "    # train = pd.read_csv('../Inputs/ball-by-ball prediction/main.csv')\n",
    "    train = pd.read_csv('../Inputs/ball-by-ball prediction/embfeats10K.csv')\n",
    "else:\n",
    "    train = pd.read_csv('embfeats10K.csv')\n",
    "    train = pd.read_csv('main.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test_split(df, target = 'target', test_size=0.1):\n",
    "    le = LabelEncoder()\n",
    "    X, y = df.drop(target, axis=1), le.fit_transform(df[target])\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, shuffle=True, random_state=RANDOM_STATE)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = get_train_test_split(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = X_train.select_dtypes(include=['object']).columns\n",
    "num_features = X_train.select_dtypes(exclude=['object']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index([], dtype='object'),\n",
       " Index(['embfeat_1', 'embfeat_2', 'embfeat_3', 'embfeat_4', 'embfeat_5',\n",
       "        'embfeat_6', 'embfeat_7', 'embfeat_8', 'embfeat_9', 'embfeat_10',\n",
       "        ...\n",
       "        'embfeat_1527', 'embfeat_1528', 'embfeat_1529', 'embfeat_1530',\n",
       "        'embfeat_1531', 'embfeat_1532', 'embfeat_1533', 'embfeat_1534',\n",
       "        'embfeat_1535', 'embfeat_1536'],\n",
       "       dtype='object', length=1536))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_features, num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_transformer = Pipeline([\n",
    "      # ('poly_feats', PolynomialFeatures(degree=2)),\n",
    "      # ('b_splines', SplineTransformer()),\n",
    "      # ('scaler', StandardScaler()),\n",
    "    #   ('bin', KBinsDiscretizer(encode='ordinal')), #only improved Lars\n",
    "      ('select_feats', SelectFromModel(lm.Lasso(random_state=RANDOM_STATE), threshold='median'))\n",
    "])\n",
    "categorical_transformer = Pipeline([\n",
    "      ('encoder', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        # ('new_feats', CustomFeatureTransformer(), num_features),\n",
    "        ('num', numeric_transformer, num_features),\n",
    "        # ('cat', categorical_transformer, cat_features)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = lm.LogisticRegression(penalty='elasticnet', solver='saga', l1_ratio=0.5, max_iter=5, n_jobs=-1)\n",
    "# model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a naive classifier\n",
    "class NaiveClassifier(BaseEstimator):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.classes_, self.counts_ = np.unique(y, return_counts=True)\n",
    "        self.prior_ = self.counts_ / len(y)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.random.choice(self.classes_, size=len(X), p=self.prior_)\n",
    "\n",
    "    def score(self, X, y):\n",
    "        return accuracy_score(y, self.predict(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipe_params={\n",
    "#     'clf__n_estimators': np.linspace(200, 1000, 100, dtype=np.int16),\n",
    "#     'clf__max_depth': np.linspace(2, 50, 10, dtype=np.int16),\n",
    "#     'clf__min_samples_split': np.linspace(2, 20, 5, dtype=np.int16),\n",
    "#     'clf__min_samples_leaf': np.linspace(2, 10, 5, dtype=np.int16),\n",
    "#     'clf__max_features': np.linspace(0.1, 1, 10, dtype=np.float16),\n",
    "#     # 'clf__learning_rate': np.linspace(0.01, 1, 50, dtype=np.float16),\n",
    "#     'clf__criterion': ['gini', 'entropy', 'log_loss'],\n",
    "#     # 'clf__bootstrap': [True, False],\n",
    "#     # 'clf__loss': ['log_loss', 'exponential'],\n",
    "#     'clf__max_samples': np.linspace(0.1, 1.0, 10, dtype=np.float16),\n",
    "#     'clf__ccp_alpha': np.linspace(0.0, 5.0, 20, dtype=np.float16),\n",
    "#     'clf__warm_start': [True, False],\n",
    "#     # 'clf__n_iter_no_change': np.linspace(1, 10, 10, dtype=np.int16),\n",
    "#     # 'clf__min_impurity_decrease': np.linspace(0.0001, 10.0, 10, dtype=np.float16),\n",
    "# }\n",
    "\n",
    "# params={\n",
    "#     'n_estimators': np.linspace(200, 1000, 100, dtype=np.int16),\n",
    "#     'max_depth': np.linspace(2, 50, 10, dtype=np.int16),\n",
    "#     'min_samples_split': np.linspace(2, 20, 5, dtype=np.int16),\n",
    "#     'min_samples_leaf': np.linspace(2, 10, 5, dtype=np.int16),\n",
    "#     'max_features': np.linspace(0.1, 1, 10, dtype=np.float16),\n",
    "#     # 'clf__learning_rate': np.linspace(0.01, 1, 50, dtype=np.float16),\n",
    "#     'criterion': ['gini', 'entropy', 'log_loss'],\n",
    "#     # 'clf__bootstrap': [True, False],\n",
    "#     # 'clf__loss': ['log_loss', 'exponential'],\n",
    "#     'max_samples': np.linspace(0.1, 1.0, 10, dtype=np.float16),\n",
    "#     'ccp_alpha': np.linspace(0.0, 5.0, 20, dtype=np.float16),\n",
    "#     'warm_start': [True, False],\n",
    "#     # 'clf__n_iter_no_change': np.linspace(1, 10, 10, dtype=np.int16),\n",
    "#     # 'clf__min_impurity_decrease': np.linspace(0.0001, 10.0, 10, dtype=np.float16),\n",
    "# }\n",
    "\n",
    "# lgbm_params={\n",
    "#     'clf__n_estimators': np.linspace(10, 200, 20, dtype=np.int16),\n",
    "#     'clf__max_depth': np.linspace(20, 100, 20, dtype=np.int16),\n",
    "#     'clf__num_leaves': np.linspace(30, 50, 10, dtype=np.int16),\n",
    "#     'clf__learning_rate': np.linspace(0.01, 0.5, 10, dtype=np.float16),\n",
    "#     'clf__subsample': np.linspace(0.8, 1.0, 10, dtype=np.float16),\n",
    "#     'clf__colsample_bytree': np.linspace(0.8, 1.0, 10, dtype=np.float16),\n",
    "#     'clf__reg_alpha': np.linspace(0.0, 0.5, 10, dtype=np.float16),\n",
    "#     'clf__reg_lambda': np.linspace(0.0, 0.5, 10, dtype=np.float16),\n",
    "#     'clf__min_child_samples': np.linspace(20, 100, 10, dtype=np.int16),\n",
    "#     'clf__min_child_weight': np.linspace(0.001, 0.1, 10, dtype=np.float16),\n",
    "#     'clf__min_split_gain': np.linspace(0.0, 1.0, 10, dtype=np.float16),\n",
    "#     'clf__subsample_freq': np.linspace(0, 10, 10, dtype=np.int16),\n",
    "#     'clf__max_bin': np.linspace(400, 600, 10, dtype=np.int16),\n",
    "#     'clf__boosting_type': ['gbdt', 'dart', 'rf', 'goss'],\n",
    "#     'clf__boost_from_average': [True, False]\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['memory', 'steps', 'verbose', 'clf', 'clf__boosting_type', 'clf__class_weight', 'clf__colsample_bytree', 'clf__importance_type', 'clf__learning_rate', 'clf__max_depth', 'clf__min_child_samples', 'clf__min_child_weight', 'clf__min_split_gain', 'clf__n_estimators', 'clf__n_jobs', 'clf__num_leaves', 'clf__objective', 'clf__random_state', 'clf__reg_alpha', 'clf__reg_lambda', 'clf__silent', 'clf__subsample', 'clf__subsample_for_bin', 'clf__subsample_freq'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Randomized Search CV - LGBM\n",
    "pipe = Pipeline([\n",
    "    # ('prep', preprocessor),\n",
    "    ('clf', LGBMClassifier(random_state=RANDOM_STATE))\n",
    "])\n",
    "pipe.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LGBMClassifier'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get classifier name\n",
    "pipe['clf'].__class__.__name__\n",
    "# pipe['clf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=&lt;generator object _BaseKFold.split at 0x14cb7c700&gt;,\n",
       "                   estimator=Pipeline(steps=[(&#x27;clf&#x27;,\n",
       "                                              LGBMClassifier(random_state=42))]),\n",
       "                   n_iter=1, n_jobs=-1,\n",
       "                   param_distributions={&#x27;clf__boost_from_average&#x27;: [True,\n",
       "                                                                    False],\n",
       "                                        &#x27;clf__boosting_type&#x27;: [&#x27;gbdt&#x27;, &#x27;dart&#x27;,\n",
       "                                                               &#x27;rf&#x27;, &#x27;goss&#x27;],\n",
       "                                        &#x27;clf__colsample_bytree&#x27;: array([0.8   , 0.8223, 0.844 , 0.8667, 0.8887, 0.911 , 0.933 , 0.9556,\n",
       "       0.97...\n",
       "                                        &#x27;clf__reg_alpha&#x27;: array([0.    , 0.1111, 0.2222, 0.3333, 0.4443, 0.5557, 0.6665, 0.778 ,\n",
       "       0.8887, 1.    ], dtype=float16),\n",
       "                                        &#x27;clf__reg_lambda&#x27;: array([0.    , 0.1111, 0.2222, 0.3333, 0.4443, 0.5557, 0.6665, 0.778 ,\n",
       "       0.8887, 1.    ], dtype=float16),\n",
       "                                        &#x27;clf__subsample&#x27;: array([0.8   , 0.8223, 0.844 , 0.8667, 0.8887, 0.911 , 0.933 , 0.9556,\n",
       "       0.9775, 1.    ], dtype=float16),\n",
       "                                        &#x27;clf__subsample_freq&#x27;: array([ 0,  1,  2,  3,  4,  5,  6,  7,  8, 10], dtype=int16)},\n",
       "                   random_state=42, scoring=&#x27;f1_weighted&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=&lt;generator object _BaseKFold.split at 0x14cb7c700&gt;,\n",
       "                   estimator=Pipeline(steps=[(&#x27;clf&#x27;,\n",
       "                                              LGBMClassifier(random_state=42))]),\n",
       "                   n_iter=1, n_jobs=-1,\n",
       "                   param_distributions={&#x27;clf__boost_from_average&#x27;: [True,\n",
       "                                                                    False],\n",
       "                                        &#x27;clf__boosting_type&#x27;: [&#x27;gbdt&#x27;, &#x27;dart&#x27;,\n",
       "                                                               &#x27;rf&#x27;, &#x27;goss&#x27;],\n",
       "                                        &#x27;clf__colsample_bytree&#x27;: array([0.8   , 0.8223, 0.844 , 0.8667, 0.8887, 0.911 , 0.933 , 0.9556,\n",
       "       0.97...\n",
       "                                        &#x27;clf__reg_alpha&#x27;: array([0.    , 0.1111, 0.2222, 0.3333, 0.4443, 0.5557, 0.6665, 0.778 ,\n",
       "       0.8887, 1.    ], dtype=float16),\n",
       "                                        &#x27;clf__reg_lambda&#x27;: array([0.    , 0.1111, 0.2222, 0.3333, 0.4443, 0.5557, 0.6665, 0.778 ,\n",
       "       0.8887, 1.    ], dtype=float16),\n",
       "                                        &#x27;clf__subsample&#x27;: array([0.8   , 0.8223, 0.844 , 0.8667, 0.8887, 0.911 , 0.933 , 0.9556,\n",
       "       0.9775, 1.    ], dtype=float16),\n",
       "                                        &#x27;clf__subsample_freq&#x27;: array([ 0,  1,  2,  3,  4,  5,  6,  7,  8, 10], dtype=int16)},\n",
       "                   random_state=42, scoring=&#x27;f1_weighted&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;clf&#x27;, LGBMClassifier(random_state=42))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(random_state=42)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=<generator object _BaseKFold.split at 0x14cb7c700>,\n",
       "                   estimator=Pipeline(steps=[('clf',\n",
       "                                              LGBMClassifier(random_state=42))]),\n",
       "                   n_iter=1, n_jobs=-1,\n",
       "                   param_distributions={'clf__boost_from_average': [True,\n",
       "                                                                    False],\n",
       "                                        'clf__boosting_type': ['gbdt', 'dart',\n",
       "                                                               'rf', 'goss'],\n",
       "                                        'clf__colsample_bytree': array([0.8   , 0.8223, 0.844 , 0.8667, 0.8887, 0.911 , 0.933 , 0.9556,\n",
       "       0.97...\n",
       "                                        'clf__reg_alpha': array([0.    , 0.1111, 0.2222, 0.3333, 0.4443, 0.5557, 0.6665, 0.778 ,\n",
       "       0.8887, 1.    ], dtype=float16),\n",
       "                                        'clf__reg_lambda': array([0.    , 0.1111, 0.2222, 0.3333, 0.4443, 0.5557, 0.6665, 0.778 ,\n",
       "       0.8887, 1.    ], dtype=float16),\n",
       "                                        'clf__subsample': array([0.8   , 0.8223, 0.844 , 0.8667, 0.8887, 0.911 , 0.933 , 0.9556,\n",
       "       0.9775, 1.    ], dtype=float16),\n",
       "                                        'clf__subsample_freq': array([ 0,  1,  2,  3,  4,  5,  6,  7,  8, 10], dtype=int16)},\n",
       "                   random_state=42, scoring='f1_weighted')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model = RandomForestClassifier(bootstrap=True, n_jobs=-1,random_state=420)\n",
    "model = \"LGBMClassifier\"\n",
    "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=RANDOM_STATE)\n",
    "rs=RandomizedSearchCV(pipe,appendclf(lgbm_params), n_iter = 1, n_jobs=-1,cv=cv.split(X_train, y_train), scoring='f1_weighted',random_state=RANDOM_STATE)\n",
    "rs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.33319195695951676,\n",
       " {'clf__subsample_freq': 5,\n",
       "  'clf__subsample': 0.8667,\n",
       "  'clf__reg_lambda': 0.6665,\n",
       "  'clf__reg_alpha': 0.1111,\n",
       "  'clf__num_leaves': 7,\n",
       "  'clf__n_estimators': 535,\n",
       "  'clf__min_split_gain': 0.8887,\n",
       "  'clf__min_child_weight': 0.001,\n",
       "  'clf__min_child_samples': 91,\n",
       "  'clf__max_depth': 7,\n",
       "  'clf__max_bin': 577,\n",
       "  'clf__learning_rate': 0.34,\n",
       "  'clf__colsample_bytree': 0.844,\n",
       "  'clf__boosting_type': 'dart',\n",
       "  'clf__boost_from_average': False})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check the validation f1 score\n",
    "rs.best_score_, rs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3641460092626899"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check the test f1 score\n",
    "predictions = rs.predict(X_test)\n",
    "f1_score(y_test, predictions, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.summary[f'cv_f1_score_{model}'] = rs['test_score'].mean()\n",
    "\n",
    "predictions = rs['estimator'][0].predict(X_test)\n",
    "wandb.summary[f'accuracy_test_{model}'] = accuracy_score(y_test, predictions)\n",
    "wandb.summary[f'f1_score_test_{model}'] = f1_score(y_test, predictions, average='weighted')\n",
    "wandb.summary[f'precision_test_{model}'] = precision_score(y_test, predictions, average='weighted')\n",
    "wandb.summary[f'recall_test_{model}'] = recall_score(y_test, predictions, average='weighted')\n",
    "\n",
    "# wandb.log('best_params', rs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2a746b357fd44018fe1e1c0f69d7d7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy_test_NaiveClassifier</td><td>0.273</td></tr><tr><td>cv_f1_score_NaiveClassifier</td><td>0.27281</td></tr><tr><td>f1_score_test_NaiveClassifier</td><td>0.27772</td></tr><tr><td>precision_test_NaiveClassifier</td><td>0.28338</td></tr><tr><td>recall_test_NaiveClassifier</td><td>0.273</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">gallant-butterfly-34</strong> at: <a href='https://wandb.ai/gsparsh/Dream11/runs/jtzj4bhm' target=\"_blank\">https://wandb.ai/gsparsh/Dream11/runs/jtzj4bhm</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230501_172200-jtzj4bhm/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = rs.best_estimator_.get_params()['clf'].get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Expected 1537 fields in line 543, saw 1682\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m/Users/sparshgupta/Projects git/Dream11/Scripts/04_parameter_sweep.ipynb Cell 20\u001b[0m in \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/sparshgupta/Projects%20git/Dream11/Scripts/04_parameter_sweep.ipynb#X40sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m data \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m'\u001b[39;49m\u001b[39membfeats10K.csv\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/sparshgupta/Projects%20git/Dream11/Scripts/04_parameter_sweep.ipynb#X40sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m X_train, X_test, y_train, y_test \u001b[39m=\u001b[39m get_train_test_split(data)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[39m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/util/_decorators.py:317\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[1;32m    312\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    313\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39marguments),\n\u001b[1;32m    314\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    315\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(inspect\u001b[39m.\u001b[39mcurrentframe()),\n\u001b[1;32m    316\u001b[0m     )\n\u001b[0;32m--> 317\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/parsers/readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    946\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[1;32m    947\u001b[0m )\n\u001b[1;32m    948\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 950\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/parsers/readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    608\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n\u001b[1;32m    610\u001b[0m \u001b[39mwith\u001b[39;00m parser:\n\u001b[0;32m--> 611\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\u001b[39m.\u001b[39;49mread(nrows)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/parsers/readers.py:1772\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1765\u001b[0m nrows \u001b[39m=\u001b[39m validate_integer(\u001b[39m\"\u001b[39m\u001b[39mnrows\u001b[39m\u001b[39m\"\u001b[39m, nrows)\n\u001b[1;32m   1766\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1767\u001b[0m     \u001b[39m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[1;32m   1768\u001b[0m     (\n\u001b[1;32m   1769\u001b[0m         index,\n\u001b[1;32m   1770\u001b[0m         columns,\n\u001b[1;32m   1771\u001b[0m         col_dict,\n\u001b[0;32m-> 1772\u001b[0m     ) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mread(  \u001b[39m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[1;32m   1773\u001b[0m         nrows\n\u001b[1;32m   1774\u001b[0m     )\n\u001b[1;32m   1775\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[1;32m   1776\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/parsers/c_parser_wrapper.py:243\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    242\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlow_memory:\n\u001b[0;32m--> 243\u001b[0m         chunks \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_reader\u001b[39m.\u001b[39;49mread_low_memory(nrows)\n\u001b[1;32m    244\u001b[0m         \u001b[39m# destructive to chunks\u001b[39;00m\n\u001b[1;32m    245\u001b[0m         data \u001b[39m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/_libs/parsers.pyx:808\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/_libs/parsers.pyx:866\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/_libs/parsers.pyx:852\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/_libs/parsers.pyx:1973\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 1537 fields in line 543, saw 1682\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('embfeats10K.csv')\n",
    "X_train, X_test, y_train, y_test = get_train_test_split(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[130], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m model \u001b[39m=\u001b[39m RandomForestClassifier(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mbest_params)\n\u001b[0;32m----> 2\u001b[0m model\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n",
      "File \u001b[0;32m~/mambaforge/envs/optim_env/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:473\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    462\u001b[0m trees \u001b[39m=\u001b[39m [\n\u001b[1;32m    463\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_estimator(append\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, random_state\u001b[39m=\u001b[39mrandom_state)\n\u001b[1;32m    464\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_more_estimators)\n\u001b[1;32m    465\u001b[0m ]\n\u001b[1;32m    467\u001b[0m \u001b[39m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[1;32m    468\u001b[0m \u001b[39m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[1;32m    469\u001b[0m \u001b[39m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[1;32m    470\u001b[0m \u001b[39m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[1;32m    471\u001b[0m \u001b[39m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[1;32m    472\u001b[0m \u001b[39m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[0;32m--> 473\u001b[0m trees \u001b[39m=\u001b[39m Parallel(\n\u001b[1;32m    474\u001b[0m     n_jobs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs,\n\u001b[1;32m    475\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[1;32m    476\u001b[0m     prefer\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mthreads\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    477\u001b[0m )(\n\u001b[1;32m    478\u001b[0m     delayed(_parallel_build_trees)(\n\u001b[1;32m    479\u001b[0m         t,\n\u001b[1;32m    480\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbootstrap,\n\u001b[1;32m    481\u001b[0m         X,\n\u001b[1;32m    482\u001b[0m         y,\n\u001b[1;32m    483\u001b[0m         sample_weight,\n\u001b[1;32m    484\u001b[0m         i,\n\u001b[1;32m    485\u001b[0m         \u001b[39mlen\u001b[39;49m(trees),\n\u001b[1;32m    486\u001b[0m         verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[1;32m    487\u001b[0m         class_weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclass_weight,\n\u001b[1;32m    488\u001b[0m         n_samples_bootstrap\u001b[39m=\u001b[39;49mn_samples_bootstrap,\n\u001b[1;32m    489\u001b[0m     )\n\u001b[1;32m    490\u001b[0m     \u001b[39mfor\u001b[39;49;00m i, t \u001b[39min\u001b[39;49;00m \u001b[39menumerate\u001b[39;49m(trees)\n\u001b[1;32m    491\u001b[0m )\n\u001b[1;32m    493\u001b[0m \u001b[39m# Collect newly grown trees\u001b[39;00m\n\u001b[1;32m    494\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_\u001b[39m.\u001b[39mextend(trees)\n",
      "File \u001b[0;32m~/mambaforge/envs/optim_env/lib/python3.11/site-packages/sklearn/utils/parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     58\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[1;32m     59\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[1;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     61\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[1;32m     62\u001b[0m )\n\u001b[0;32m---> 63\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[0;32m~/mambaforge/envs/optim_env/lib/python3.11/site-packages/joblib/parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1095\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m   1097\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1098\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mretrieve()\n\u001b[1;32m   1099\u001b[0m \u001b[39m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m elapsed_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_start_time\n",
      "File \u001b[0;32m~/mambaforge/envs/optim_env/lib/python3.11/site-packages/joblib/parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    973\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    974\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, \u001b[39m'\u001b[39m\u001b[39msupports_timeout\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m--> 975\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout))\n\u001b[1;32m    976\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    977\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39mget())\n",
      "File \u001b[0;32m~/mambaforge/envs/optim_env/lib/python3.11/multiprocessing/pool.py:768\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    767\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget\u001b[39m(\u001b[39mself\u001b[39m, timeout\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 768\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[1;32m    769\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mready():\n\u001b[1;32m    770\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/optim_env/lib/python3.11/multiprocessing/pool.py:765\u001b[0m, in \u001b[0;36mApplyResult.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    764\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwait\u001b[39m(\u001b[39mself\u001b[39m, timeout\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 765\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_event\u001b[39m.\u001b[39;49mwait(timeout)\n",
      "File \u001b[0;32m~/mambaforge/envs/optim_env/lib/python3.11/threading.py:622\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    620\u001b[0m signaled \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flag\n\u001b[1;32m    621\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 622\u001b[0m     signaled \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cond\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[1;32m    623\u001b[0m \u001b[39mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m~/mambaforge/envs/optim_env/lib/python3.11/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[1;32m    321\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(**best_params)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = rs.predict(X_test)\n",
    "f1_score(y_test, predictions, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['venue', 'innings', 'batting_team', 'bowling_team', 'striker',\n",
       "       'non_striker', 'bowler', 'overs', 'balls', 'bat_0_runs', 'bat_1_runs',\n",
       "       'bat_2_runs', 'bat_3_runs', 'bat_4_runs', 'bat_6_runs',\n",
       "       'bat_num_dismissals', 'bat_wides', 'bat_total_balls', 'bowl_0_runs',\n",
       "       'bowl_1_runs', 'bowl_2_runs', 'bowl_3_runs', 'bowl_4_runs',\n",
       "       'bowl_6_runs', 'bowl_num_dismissals', 'bowl_wides', 'bowl_total_balls'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps:\n",
    "1. Evaluate more classifiers (LGBM, XGBoost, Bagging, GBR, ExtraTrees) on the same dataset using StratifiedKFold, shuffle=True (in TTS)\n",
    "2. Repeat step-1 using TimeSeriesSplit, shuffle=False (in TTS)\n",
    "3. Use feature transformers (power, kbins, spline), repeat step-1,2\n",
    "4. create ensemble models from step-1,2 and evaluate\n",
    "5. create ensemble models using step-3 and evaluate\n",
    "6. create new target using (dots, runs, four, six, wicket labels) repeat step-1to5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
